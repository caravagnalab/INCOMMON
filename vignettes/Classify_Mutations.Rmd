---
title: "Classify mutations from a targeted sequencing sample"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Classify mutations from a targeted sequencing sample}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

options(crayon.enabled=TRUE)
```

```{r setup}
library(dplyr)
library(INCOMMON)
```

We work with the [example INCOMMON `data`](INCOMMON.html).

```{r, include=FALSE}
print(example_data)
```

## A Beta-Binomial mixture model for classification

INCOMMON implements a maximum a posteriori classifier to infer the copy number ($n_A$ for the major allele, $n_B$ 
for the minor) and multiplicity $m$ of mutations from read-count data.

The classifier is based on a Beta-Binomial mixture model, in which the number of reads with a variant ($NV$) is the number of events
and the sequencing depth $DP$ is the total number of trials.

A mutation on a genomic site of ploidy $p = n_A+n_B$, with multiplicity $m\leq \max(n_A,n_B)$, in a sample of purity $\pi$
has an expected VAF of
\[
\mathbb{E}[\text{VAF}] = \frac{m\pi}{p\pi + 2\left(1-\pi\right)}
\] 

In the read counting process this represents the event probability. Therefore, based
on mutation data

- $NV$ reads with the variant at the locus;
- $DP$ coverage at the locus;
- sample purity $\pi$;

the likelihood of observing $NV$ reads with the variant is
\[
P(X = NV | \theta_\eta,\rho, DP) = \text{Beta-Binonmial}\left(NV \;\large\mid\;\normalsize \theta_\eta, \rho, DP\right)
\] 

> Setting $\rho = 0$ corresponds to using a pure Binomial model with no model of the sequencer overdispersion. 

## Example 

In the following example, the classification task is run using the default setting $\rho = 0.01$.

The input must be prepared using function `init`:
```{r}
input = init(mutations = example_data$data,
             sample = example_data$sample,
             purity = example_data$purity,
             tumor_type = example_data$tumor_type,
             gene_roles = cancer_gene_census)
print(input)
```
This is a lung adenocarcinoma (LUAD) sample "P-0002081-T01-IM3" from the MSK-MetTropsim dataset.
The sample has purity $\pi = 0.6$ and contains mutations called on genes KRAS, TP53, STK11 and SMARCA4.
A column `gene_role` is extracted from the COSMIC Cancer Gene Census (default) catalogue and 
attached to the input data according to gene names. Other sources for gene roles can
be input by the user through option `gene_roles` of function `init`.

INCOMMON classification of a sample can be performed using function `classify`. 
Here we do not use any prior knowledge and no cut-off on the classification entropy.

```{r}
out = classify(
  x = input,
  priors = NULL,
  entropy_cutoff = NULL,
  rho = 0.01
)
print(out)
```
The results of the classification  can be visualized using the internal 
plotting function. Here is an example:
```{r}
plot_classification(out)
```

All mutations are classified as with amplification. However, visual inspection of the plots
suggest that only the mutation on KRAS has low entropy $H(x) \leq 0.2$. In effect, it is the only
mutation with high sequencing depth $DP\geq500$.

Given the lower depth, the number of reads with the variant $NV$ (vertical line) for the other mutations is compatible with multiple copy number
configurations, which are thus assigned similar posterior probabilities.

## Using priors and the entropy cut-off.

The classification can be made easier by injecting prior knowledge into the model.
In function `classify`, the user can provide a table as argument `prior`. INCOMMON
provides an internal table of prior distributions obtained from PCAWG whole-genomes:

```{r}
pcawg_priors
```

We know classify mutations using this priors. Since we are biasing the classification
with prior knowledge, it is now reasonable also to make the classification stricter
by using a cut-off on the entropy. The default value for `entropy_cutoff` is $0.20$.
Mutations with classification entropy above this cutoff will be flagged as Tier-2.

```{r}
out = classify(
  x = input,
  priors = pcawg_priors,
  entropy_cutoff = 0.2,
  rho = 0.01
)
print(out)
```

Tumour suppressor genes TP53, STK11 and SMARCA4 have high frequency of LOH in PCAWG,
and low frequency of amplification. Injecting this prior knowledge into the model
pushes the classification outcome towards this states. The effect of using the prior 
is evident from the classification plots:
```{r}
plot_classification(out)
```
